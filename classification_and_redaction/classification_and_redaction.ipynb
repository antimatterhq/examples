{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f45b742050318",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install antimatter==2.0.1 pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb491f486b1bdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import antimatter as am\n",
    "import pandas\n",
    "import json\n",
    "\n",
    "pandas.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Change to your business email address to create a free account.\n",
    "# Follow the link in your inbox to verify email address before proceeding.\n",
    "my_email_address = \"email@sample.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560117ef20180af",
   "metadata": {},
   "source": [
    "First thing we do is create an Antimatter domain. This can be done with the CLI, or with the python library. \n",
    "\n",
    "To make it easier to run the notebook, we'll save our credentials for the created domain and re-use them if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036698bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into (or create) an Antimatter domain, re-using the saved domain if it's found\n",
    "try:\n",
    "    amr = am.load_domain(config_path=my_email_address+\".cfg\")\n",
    "    # double check domain is verified\n",
    "    _ = amr.list_read_context()\n",
    "except am.errors.errors.SessionLoadError as e:\n",
    "    # Failed to load, create a new domain\n",
    "    amr = am.new_domain(email=my_email_address, make_active=True, config_path=my_email_address+\".cfg\")\n",
    "    raise Exception(f\"New domain created. Check your email address ({my_email_address}) and click the link to verify, then re-Run All to proceed.\")\n",
    "except am.errors.errors.SessionError as e:\n",
    "    if \"domain not authenticated\" in str(e):\n",
    "        # amr.resend_verification_email(my_email_address)\n",
    "        raise Exception (f\"Domain not verified. Check your email address ({my_email_address}) and click the link to verify, then re-Run All to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a80a7b64e69432",
   "metadata": {},
   "source": [
    "If this is the first time you have run the notebook, this will have sent a confirmation email to your email address (it can take a few minutes). \n",
    "\n",
    "**Click the button in the email to activate your domain before proceeding.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62d9c48db9e20c",
   "metadata": {},
   "source": [
    "Now that we have an Antimatter domain, let's see how we can use Antimatter to classify some sensitive data and redact it. Let's load a parquet file that contains a mix of structured data and embedded unstructured data (a comments column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ebaa56a98361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_parquet(\"https://get.antimatter.io/data/example_data.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35fa0b1d4f2514",
   "metadata": {},
   "source": [
    "You can see that we have a bunch of data here that would probably be considered sensitive in some contexts. Some of it is in clearly labelled columns, which might be easy to deal with manually, but some of it is embedded within free-form text in the comments column. That's pretty common whenever you are storing data coming from users: they can (and often do) enter sensitive info that needs special handling.\n",
    "\n",
    "Let's *encapsulate* this data. A capsule is Antimatter's object format for tagged data. It stores the full set of data, as well as all the classification tags. It's encrypted, so can be stored anywhere without worrying that sensitive data might be accessible to those who can access the object. Having an intermediate file format lets you do the classification once, and then re-use multiple times. This is convenient, because classification is often fairly heavyweight.\n",
    "\n",
    "When we encapsulate, we have to specify a *write_context* that contains the configuration for which classifiers to run on the data. New domains come with a `default` write context that does no classification, and a `sensitive` write context that uses the `fast-pii` classifier to tag common PII. You can change the configuration of these write contexts or add new ones as needed, but we're going to just use `sensitive` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9e08169108243",
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule = amr.encapsulate(df, write_context=\"sensitive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774521d9371ceb0",
   "metadata": {},
   "source": [
    "Once the classification is done, we can write the capsule to a file, or just use it directly to read the data. When reading data, you need to specify a `read_context` which contains the configuration for what redaction and transformation should occur on the data. New domains come with a `default` read context which does no redaction, but we will add some rules to it in a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838bf4e0106ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule.save(\"mycapsule.ca\")\n",
    "data = amr.load_capsule(data=capsule, read_context=\"default\").data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eef86dec8066dc",
   "metadata": {},
   "source": [
    "You will notice that what we got back was a Pandas dataframe. Antimatter stores some information about the shape of the data during encapsulation, and automatically presents the data in the same form when reading (in this case, a Pandas dataframe). This lets you insert Antimatter into your data pipeline without impacting any of the operations that happen after the read. You can use `.data_as()` instead of `.data()` if you'd like to read the data in a different format.\n",
    "\n",
    "So now, let's do some redaction. This is achieved by bind a data policy rule to the read context. Data policy rules can be fairly complex, to deal with advanced cases like reproducing permissions that existed in the original source of data, but we're going to make a simple one that just references a Tag and redacts if it exists. \n",
    "\n",
    "First we make a data policy and the save the ID. Next, we can update the policy rules and add our new policy to redact email addresses. Once we have our data policy configured to our liking, we can bind it to read context to ensure it gets used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2bec4-7476-4a6a-a6db-f14a575b6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data policy and save its ID\n",
    "res = amr.create_data_policy(\"my_data_policy\", \"sample description\")\n",
    "policy_id = res.policy_id\n",
    "\n",
    "# update the data policy with rules to redact email addresses\n",
    "email_rule = amr.update_data_policy_rules(\n",
    "    policy_id=policy_id,\n",
    "    rules=am.DataPolicyRuleChangesBuilder().add_rule(\n",
    "        am.NewDataPolicyRuleBuilder(comment=\"Deny\", effect=am.RuleEffect.REDACT, priority=10).add_clause(\n",
    "            clause=am.DataPolicyClauseBuilder(am.ClauseOperator.AnyOf).add_tag(\n",
    "                am.TagExpressionBuilder()\n",
    "                .set_name(\"tag.antimatter.io/pii/email_address\")\n",
    "                .set_operator(am.Operator.Exists)\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# bind the data policy to the default read context\n",
    "amr.set_data_policy_binding(\n",
    "    policy_id=policy_id,\n",
    "    default_attachment=am.Attachment.NotAttached,\n",
    "    read_contexts=[(\"default\", am.Attachment.Attached)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b833074de15cb0b",
   "metadata": {},
   "source": [
    "Now, if we read the data again, we'll see that names have been redacted in both the name columns, but also in the comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0deff5eb669fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr.load_capsule(data=capsule, read_context=\"default\").data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fbf75db6efcde8",
   "metadata": {},
   "source": [
    "We added the rule to the `default` read context, but the purpose of read contexts is to be able to capture policy about what data can be used in which conditions. So you might have different read contexts for use cases (e.g. model training) or for different teams (e.g. fraud). Let's make a new read context for `analytics` and configure some data policy rules to redact more of the PII in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c21dd-a507-4632-b3d0-49e322194621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the \"analytics\" read context\n",
    "amr.add_read_context(\"analytics\",\n",
    "    am.ReadContextBuilder().\n",
    "        set_summary(\"Analytics read context\").\n",
    "        set_description(\"Read context for data analysis\").\n",
    "        add_required_hook(am.Hook.Fast)\n",
    ")\n",
    "\n",
    "# create a new data policy and save its ID\n",
    "res = amr.create_data_policy(\"analytics_data_policy\", \"policies related to the analysis of data\")\n",
    "policy_id = res.policy_id\n",
    "\n",
    "# update the data policy with rules to redact PII\n",
    "amr.update_data_policy_rules(\n",
    "    policy_id=policy_id,\n",
    "    rules=am.DataPolicyRuleChangesBuilder().add_rule(\n",
    "        am.NewDataPolicyRuleBuilder(comment=\"Deny\", effect=am.RuleEffect.REDACT, priority=10)\n",
    "        .add_clause(\n",
    "            clause=am.DataPolicyClauseBuilder(am.ClauseOperator.AnyOf)\n",
    "            .add_tag(\n",
    "                am.TagExpressionBuilder()\n",
    "                .set_name(\"tag.antimatter.io/pii/name\")\n",
    "                .set_operator(am.Operator.Exists)\n",
    "            )\n",
    "            .add_tag(\n",
    "                am.TagExpressionBuilder()\n",
    "                .set_name(\"tag.antimatter.io/pii/email_address\")\n",
    "                .set_operator(am.Operator.Exists)\n",
    "            )\n",
    "            .add_tag(\n",
    "                am.TagExpressionBuilder()\n",
    "                .set_name(\"tag.antimatter.io/pii/ssn\")\n",
    "                .set_operator(am.Operator.Exists)\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# bind the data policy to the analytics read context\n",
    "amr.set_data_policy_binding(\n",
    "    policy_id=policy_id,\n",
    "    default_attachment=am.Attachment.NotAttached,\n",
    "    read_contexts=[(\"analytics\", am.Attachment.Attached)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b66d2d9dca5a4",
   "metadata": {},
   "source": [
    "Now, if we load the capsule again, we'll see that more of the PII has been redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644369ce6ea0e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr.load_capsule(data=capsule, read_context=\"analytics\").data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ca75f2a001918",
   "metadata": {},
   "source": [
    "You can see which tags are available to reference in your rules by calling `list_hooks`. The `sensitive` write context uses `fast-pii` by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b932ee5b62848f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr.list_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa69d417d061c6",
   "metadata": {},
   "source": [
    "One of the advantages of using Antimatter is that the policy captured in the read context is separate from your data pipeline. Often, the rules of what data is allowed to be used by whom are actually decided by different stakeholders (e.g. the security or legal teams) rather than by the folks who are doing data cleaning and augmentation for the purposes of analytics. \n",
    "\n",
    "The data policy rules can be configured by anyone who is invited to the domain, using the python libraries, the command line tool, or the web app. Let's create an API key for a colleague on the security team to configure the read contexts. For simplicity, we'll make them an `admin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ce4e2adb16a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apik = amr.insert_identity_provider_principal('apikey',\n",
    "    capabilities={'admin':None}, \n",
    "    principal_type=am.PrincipalType.ApiKey)\n",
    "print (f\"Login with --domain-id={amr.config()['domain_id']} --api-key={apik.api_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8630d5fe4edd072",
   "metadata": {},
   "source": [
    "They can use the CLI (for example) to interact with the domain like this:\n",
    "\n",
    "```bash\n",
    "# get the latest Antimatter CLI:\n",
    "$ sudo curl https://get.antimatter.io/cli/darwin/arm64/am -o /usr/local/bin/am\n",
    "$ sudo chmod a+x /usr/local/bin/am\n",
    "\n",
    "$ am config domain login --domain-id dm-xxxxxxxxxxx --api-key xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "$ am read-context list\n",
    "readContexts:\n",
    "- name: analytics\n",
    "  summary: Analytics read context\n",
    "  description: Read context for data analysis\n",
    "  disableReadLogging: false\n",
    "  keyCacheTTL: 0\n",
    "  readParameters: []\n",
    "  imported: false\n",
    "- name: default\n",
    "  summary: Default read context\n",
    "  description: The default read context\n",
    "  disableReadLogging: false\n",
    "  keyCacheTTL: 0\n",
    "  readParameters: []\n",
    "  imported: false\n",
    "```\n",
    "\n",
    "In order to create a new data policy rule, they will need the existing policy's ID. Below we are using the [yq](https://mikefarah.gitbook.io/yq) command line tool but you can also just use `am data-policy list` without yq and copy the ID for the data policy named `analytics_data_policy`.\n",
    "\n",
    "```bash\n",
    "$ POLICY_ID=$(am data-policy list | yq '.policies[] | select(.name == \"analytics_data_policy\") | .id')\n",
    "```\n",
    "\n",
    "Our colleague can then add a new data policy rule, e.g. to redact physical addresses like this:\n",
    "\n",
    "```bash\n",
    "$ am data-policy rule create \\\n",
    "  --policy-id $POLICY_ID \\\n",
    "  --effect Redact \\\n",
    "  --priority 20 \\\n",
    "  --clause '{\"operator\": \"AnyOf\", \"tags\": [{\"name\": \"tag.antimatter.io/pii/location\", \"values\": [], \"operator\": \"Exists\"}]}'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc506e762230013",
   "metadata": {},
   "source": [
    "Now, if we read the same capsule as before, we will see that addresses have been redacted. We don't need to re-encapsulate or re-materialize any datasets. For example purposes, lets read it from the file instead of using the `capsule` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbaccdf2c7d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we saved \"mycapsule.ca\" earlier\n",
    "amr.load_capsule(path=\"mycapsule.ca\",read_context=\"analytics\").data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7bec42e439cd8",
   "metadata": {},
   "source": [
    "You can see that the addresses are now redacted too.\n",
    "\n",
    "We used a Pandas dataframe above, but you can encapsulate data of multiple different shapes. For example, even a plain string can be encapsulated by itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669877a01d6c9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cap = amr.encapsulate(\n",
    "    \"\"\"\n",
    "    This works with arbitrary data, e.g. 'contact Alan McKinsey at some@email.com'\",\n",
    "    We support many shapes of data, like strings, dicts, lists of dicts, pandas dataframes, pytorch data loaders etc\n",
    "    \"\"\", write_context=\"sensitive\")\n",
    "print(amr.load_capsule(data=string_cap, read_context=\"analytics\").data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also try it with your own data. NOTE: This will redact name, emails and SSNs\n",
    "#  Try filling in some text here:\n",
    "sentence = \"my social is 555 55 5555\"\n",
    "amr.classify_and_redact(sentence, write_context=\"sensitive\", read_context=\"analytics\").data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d226c22aa13c8c",
   "metadata": {},
   "source": [
    "For more information, please see [the docs](https://docs.antimatter.io)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
